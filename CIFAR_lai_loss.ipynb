{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5429a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7949a536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 13:45:58,705 - Device <cpu> is selected\n",
      "2025-04-15 13:46:02,591 - PyTorch version 2.3.1 available.\n"
     ]
    }
   ],
   "source": [
    "from fedcore.tools.example_utils import get_scenario_for_api\n",
    "from fedcore.api.main import FedCore\n",
    "from fedcore.api.utils.checkers_collection import ApiConfigCheck\n",
    "from fedcore.data.dataloader import load_data\n",
    "from fedcore.api.utils.evaluation import evaluate_original_model, evaluate_optimised_model\n",
    "from fedcore.repository.config_repository import DEFAULT_CLF_API_CONFIG\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "from fedcore.api.config_factory import ConfigFactory\n",
    "from fedcore.api.api_configs import (\n",
    "    APIConfigTemplate, DeviceConfigTemplate, AutoMLConfigTemplate,\n",
    "    LearningConfigTemplate, NeuralModelConfigTemplate, ComputeConfigTemplate, FedotConfigTemplate,\n",
    "    LowRankTemplate)\n",
    "from fedcore.architecture.dataset.api_loader import ApiLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac1ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_assumption = resnet18(ResNet18_Weights)\n",
    "\n",
    "DATASET = 'CIFAR10'\n",
    "DATASET_PARAMS = {'train_bs': 64,\n",
    "                  'val_bs': 100,\n",
    "                  'train_shuffle': True,\n",
    "                  'val_shuffle': False}\n",
    "\n",
    "METRIC_TO_OPTIMISE = ['accuracy', 'latency', 'throughput']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a4936a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "APIConfig = ConfigFactory.from_template(\n",
    "    APIConfigTemplate(\n",
    "        None,\n",
    "        AutoMLConfigTemplate(\n",
    "            FedotConfigTemplate(\n",
    "            problem='classification',\n",
    "            pop_size=1,\n",
    "            timeout=1,\n",
    "            initial_assumption=initial_assumption\n",
    "            )\n",
    "        ),\n",
    "        LearningConfigTemplate(\n",
    "            criterion='cross_entropy',\n",
    "            learning_strategy='from_scratch',\n",
    "            peft_strategy='low_rank',\n",
    "            peft_strategy_params=LowRankTemplate(\n",
    "                epochs=1,\n",
    "                non_adaptive_threshold=0.1\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e4916f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_config = APIConfig() # Here we can update with kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df94b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = load_data(DATASET)\n",
    "al = ApiLoader('CIFAR10', {'split_ratio': [0.6, 0.4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e42640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_data = al._convert_to_fedcore(al._init_pretrain_dataset(al.source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d2ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dask Server\n",
      "2025-04-15 13:46:17,742 - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "2025-04-15 13:46:17,947 - State start\n",
      "2025-04-15 13:46:18,064 -   Scheduler at: inproc://192.168.1.76/12496/1\n",
      "2025-04-15 13:46:18,068 -   dashboard at:  http://192.168.1.76:8787/status\n",
      "2025-04-15 13:46:18,131 -       Start worker at: inproc://192.168.1.76/12496/4\n",
      "2025-04-15 13:46:18,134 -          Listening to:         inproc192.168.1.76\n",
      "2025-04-15 13:46:18,135 -           Worker name:                          0\n",
      "2025-04-15 13:46:18,138 -          dashboard at:         192.168.1.76:63299\n",
      "2025-04-15 13:46:18,139 - Waiting to connect to: inproc://192.168.1.76/12496/1\n",
      "2025-04-15 13:46:18,141 - -------------------------------------------------\n",
      "2025-04-15 13:46:18,143 -               Threads:                          4\n",
      "2025-04-15 13:46:18,147 -                Memory:                   3.44 GiB\n",
      "2025-04-15 13:46:18,150 -       Local Directory: C:\\Users\\User\\AppData\\Local\\Temp\\dask-scratch-space\\worker-rjykifls\n",
      "2025-04-15 13:46:18,152 - -------------------------------------------------\n",
      "2025-04-15 13:46:18,165 - Register worker <WorkerState 'inproc://192.168.1.76/12496/4', name: 0, status: init, memory: 0, processing: 0>\n",
      "2025-04-15 13:46:18,172 - Starting worker compute stream, inproc://192.168.1.76/12496/4\n",
      "2025-04-15 13:46:18,174 - Starting established connection to inproc://192.168.1.76/12496/5\n",
      "2025-04-15 13:46:18,177 -         Registered to: inproc://192.168.1.76/12496/1\n",
      "2025-04-15 13:46:18,184 - -------------------------------------------------\n",
      "2025-04-15 13:46:18,188 - Starting established connection to inproc://192.168.1.76/12496/1\n",
      "2025-04-15 13:46:18,206 - Receive client connection: Client-dc8d99fa-19e6-11f0-b0d0-0897989e927f\n",
      "2025-04-15 13:46:18,215 - Starting established connection to inproc://192.168.1.76/12496/6\n",
      "Triggered OptimizerGen at 1 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch #:   7%|▋         | 279/3750 [05:04<49:34,  1.17it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 13:51:49,566 - Failed to reconnect to scheduler after 30.00 seconds, closing client\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch #: 100%|██████████| 3750/3750 [51:45<00:00,  1.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Truncate rank for each weight matrix=================\n",
      "After rank pruning left only 87.5 % of conv1 layer params\n",
      "After rank pruning left only 87.5 % of layer1.0.conv1 layer params\n",
      "After rank pruning left only 87.5 % of layer1.0.conv2 layer params\n",
      "After rank pruning left only 87.5 % of layer1.1.conv1 layer params\n",
      "After rank pruning left only 87.5 % of layer1.1.conv2 layer params\n",
      "After rank pruning left only 87.5 % of layer2.0.conv1 layer params\n",
      "After rank pruning left only 87.5 % of layer2.0.conv2 layer params\n",
      "After rank pruning left only 87.5 % of layer2.0.downsample.0 layer params\n",
      "After rank pruning left only 87.5 % of layer2.1.conv1 layer params\n",
      "After rank pruning left only 87.5 % of layer2.1.conv2 layer params\n",
      "After rank pruning left only 89.0625 % of layer3.0.conv1 layer params\n",
      "After rank pruning left only 89.0625 % of layer3.0.conv2 layer params\n",
      "After rank pruning left only 87.5 % of layer3.0.downsample.0 layer params\n",
      "After rank pruning left only 89.0625 % of layer3.1.conv1 layer params\n",
      "After rank pruning left only 89.0625 % of layer3.1.conv2 layer params\n",
      "After rank pruning left only 89.84375 % of layer4.0.conv1 layer params\n",
      "After rank pruning left only 89.84375 % of layer4.0.conv2 layer params\n",
      "After rank pruning left only 89.0625 % of layer4.0.downsample.0 layer params\n",
      "After rank pruning left only 89.84375 % of layer4.1.conv1 layer params\n",
      "After rank pruning left only 89.84375 % of layer4.1.conv2 layer params\n",
      "After rank pruning left only 89.85684375547923 % of fc layer params\n",
      "torch.Size([56])\n",
      "torch.Size([56])\n",
      "torch.Size([56])\n",
      "torch.Size([56])\n",
      "torch.Size([56])\n",
      "torch.Size([112])\n",
      "torch.Size([112])\n",
      "torch.Size([56])\n",
      "torch.Size([112])\n",
      "torch.Size([112])\n",
      "torch.Size([228])\n",
      "torch.Size([228])\n",
      "torch.Size([112])\n",
      "torch.Size([228])\n",
      "torch.Size([228])\n",
      "torch.Size([460])\n",
      "torch.Size([460])\n",
      "torch.Size([228])\n",
      "torch.Size([460])\n",
      "torch.Size([460])\n",
      "==============Finetune truncated model=================\n",
      "Triggered OptimizerGen at 1 epoch.\n",
      "Triggered OptimizerGen at 1 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch #: 100%|██████████| 3750/3750 [33:47<00:00,  1.85it/s]\n",
      "Batch #: 100%|██████████| 3750/3750 [32:39<00:00,  1.91it/s]\n",
      "Batch #: 100%|██████████| 3750/3750 [33:24<00:00,  1.87it/s]\n",
      "Batch #:  95%|█████████▍| 3555/3750 [41:09<03:23,  1.04s/it]  "
     ]
    }
   ],
   "source": [
    "fedcore_compressor = FedCore(api_config)\n",
    "fedcore_compressor.fit_no_evo(input_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25cb13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
